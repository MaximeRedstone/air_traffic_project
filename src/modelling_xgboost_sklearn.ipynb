{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import os, sys\n",
    "\n",
    "# sys.path.append(\"~/X/PythonForDataScience/air_traffic_project/submissions/first_real_submission/\")\n",
    "\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from problem import *\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "import geopy.distance\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from model_selection_python import *\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "\n",
    "from six import StringIO  \n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "import os\n",
    "\n",
    "from estimator import _merge_external_data\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Dense,Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.metrics import RootMeanSquaredError\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxime/X/PythonForDataScience/air_traffic_project/src/estimator.py:40: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n",
      "  X_encoded.loc[:, 'week'] = X_encoded['DateOfDeparture'].dt.week\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = get_train_data('..')\n",
    "X_test, y_test = get_test_data('..')\n",
    "\n",
    "X_train_merged = _merge_external_data(X_train)\n",
    "X_test_merged = _merge_external_data(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_keep = ['WeeksToDeparture', 'week_mean', 'day_mean', 'month_mean', 'day_nb_mean', \n",
    "                   'route_mean', 'std_wtd', 'n_days_departure',\n",
    "                   'distance', 'mean_per_flight_arr']\n",
    "\n",
    "X_train_data = X_train_merged[features_to_keep]\n",
    "X_test_data = X_test_merged[features_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.419089\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.5, learning_rate = 0.1,\n",
    "               alpha = 10, n_estimators = 100)\n",
    "xg_reg.fit(X_train_data, y_train)\n",
    "\n",
    "preds = xg_reg.predict(X_test_data)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "print(\"RMSE: %f\" % (rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-rmse-mean</th>\n",
       "      <th>train-rmse-std</th>\n",
       "      <th>test-rmse-mean</th>\n",
       "      <th>test-rmse-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.497959</td>\n",
       "      <td>0.004345</td>\n",
       "      <td>9.497994</td>\n",
       "      <td>0.018937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.556368</td>\n",
       "      <td>0.003432</td>\n",
       "      <td>8.556613</td>\n",
       "      <td>0.019293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.710062</td>\n",
       "      <td>0.003595</td>\n",
       "      <td>7.710767</td>\n",
       "      <td>0.019481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.948904</td>\n",
       "      <td>0.003642</td>\n",
       "      <td>6.949960</td>\n",
       "      <td>0.019896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.263883</td>\n",
       "      <td>0.003460</td>\n",
       "      <td>6.264859</td>\n",
       "      <td>0.019880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.648160</td>\n",
       "      <td>0.003684</td>\n",
       "      <td>5.649071</td>\n",
       "      <td>0.019056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.096299</td>\n",
       "      <td>0.003351</td>\n",
       "      <td>5.097878</td>\n",
       "      <td>0.019696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.598879</td>\n",
       "      <td>0.003723</td>\n",
       "      <td>4.600709</td>\n",
       "      <td>0.020206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.151854</td>\n",
       "      <td>0.003008</td>\n",
       "      <td>4.153995</td>\n",
       "      <td>0.019906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.749437</td>\n",
       "      <td>0.002233</td>\n",
       "      <td>3.751680</td>\n",
       "      <td>0.020141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.389519</td>\n",
       "      <td>0.002171</td>\n",
       "      <td>3.392068</td>\n",
       "      <td>0.019873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.064223</td>\n",
       "      <td>0.002878</td>\n",
       "      <td>3.066381</td>\n",
       "      <td>0.020285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.773485</td>\n",
       "      <td>0.003946</td>\n",
       "      <td>2.776073</td>\n",
       "      <td>0.019961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.512214</td>\n",
       "      <td>0.003824</td>\n",
       "      <td>2.515039</td>\n",
       "      <td>0.018326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.279449</td>\n",
       "      <td>0.002274</td>\n",
       "      <td>2.282171</td>\n",
       "      <td>0.017713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.069671</td>\n",
       "      <td>0.002750</td>\n",
       "      <td>2.073251</td>\n",
       "      <td>0.018424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.883284</td>\n",
       "      <td>0.003282</td>\n",
       "      <td>1.887193</td>\n",
       "      <td>0.018319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.715550</td>\n",
       "      <td>0.005563</td>\n",
       "      <td>1.719684</td>\n",
       "      <td>0.018699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.564165</td>\n",
       "      <td>0.005607</td>\n",
       "      <td>1.568890</td>\n",
       "      <td>0.017384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.430843</td>\n",
       "      <td>0.005315</td>\n",
       "      <td>1.436255</td>\n",
       "      <td>0.016418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.311828</td>\n",
       "      <td>0.006668</td>\n",
       "      <td>1.318105</td>\n",
       "      <td>0.017299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.208458</td>\n",
       "      <td>0.007030</td>\n",
       "      <td>1.214859</td>\n",
       "      <td>0.016349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.114755</td>\n",
       "      <td>0.008337</td>\n",
       "      <td>1.122041</td>\n",
       "      <td>0.017085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.033332</td>\n",
       "      <td>0.009191</td>\n",
       "      <td>1.041271</td>\n",
       "      <td>0.018078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.961930</td>\n",
       "      <td>0.010448</td>\n",
       "      <td>0.970798</td>\n",
       "      <td>0.019660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.897111</td>\n",
       "      <td>0.012141</td>\n",
       "      <td>0.906443</td>\n",
       "      <td>0.021895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.841684</td>\n",
       "      <td>0.013104</td>\n",
       "      <td>0.851702</td>\n",
       "      <td>0.023431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.790634</td>\n",
       "      <td>0.012309</td>\n",
       "      <td>0.801245</td>\n",
       "      <td>0.022965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.747396</td>\n",
       "      <td>0.011510</td>\n",
       "      <td>0.758697</td>\n",
       "      <td>0.021962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.710069</td>\n",
       "      <td>0.011478</td>\n",
       "      <td>0.722497</td>\n",
       "      <td>0.023274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.676798</td>\n",
       "      <td>0.010482</td>\n",
       "      <td>0.689679</td>\n",
       "      <td>0.022536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.649833</td>\n",
       "      <td>0.011128</td>\n",
       "      <td>0.663249</td>\n",
       "      <td>0.023977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.626945</td>\n",
       "      <td>0.011872</td>\n",
       "      <td>0.641061</td>\n",
       "      <td>0.024799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.605798</td>\n",
       "      <td>0.012869</td>\n",
       "      <td>0.620460</td>\n",
       "      <td>0.025779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.585154</td>\n",
       "      <td>0.011862</td>\n",
       "      <td>0.600607</td>\n",
       "      <td>0.025355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.567107</td>\n",
       "      <td>0.011742</td>\n",
       "      <td>0.583331</td>\n",
       "      <td>0.025499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.552769</td>\n",
       "      <td>0.009682</td>\n",
       "      <td>0.569542</td>\n",
       "      <td>0.024199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.541200</td>\n",
       "      <td>0.008373</td>\n",
       "      <td>0.558353</td>\n",
       "      <td>0.023160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.530449</td>\n",
       "      <td>0.009666</td>\n",
       "      <td>0.548227</td>\n",
       "      <td>0.024140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.520177</td>\n",
       "      <td>0.010962</td>\n",
       "      <td>0.538169</td>\n",
       "      <td>0.026250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.513004</td>\n",
       "      <td>0.011455</td>\n",
       "      <td>0.531504</td>\n",
       "      <td>0.026922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.506669</td>\n",
       "      <td>0.011755</td>\n",
       "      <td>0.525638</td>\n",
       "      <td>0.027251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.500286</td>\n",
       "      <td>0.011491</td>\n",
       "      <td>0.519747</td>\n",
       "      <td>0.027241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.494668</td>\n",
       "      <td>0.010500</td>\n",
       "      <td>0.514585</td>\n",
       "      <td>0.026623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.489372</td>\n",
       "      <td>0.011561</td>\n",
       "      <td>0.509709</td>\n",
       "      <td>0.028374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.482628</td>\n",
       "      <td>0.011001</td>\n",
       "      <td>0.503237</td>\n",
       "      <td>0.028741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.478540</td>\n",
       "      <td>0.009045</td>\n",
       "      <td>0.499483</td>\n",
       "      <td>0.027536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.474825</td>\n",
       "      <td>0.006951</td>\n",
       "      <td>0.496148</td>\n",
       "      <td>0.026275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.471242</td>\n",
       "      <td>0.006596</td>\n",
       "      <td>0.493428</td>\n",
       "      <td>0.026176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.467256</td>\n",
       "      <td>0.005879</td>\n",
       "      <td>0.489847</td>\n",
       "      <td>0.025799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train-rmse-mean  train-rmse-std  test-rmse-mean  test-rmse-std\n",
       "0          9.497959        0.004345        9.497994       0.018937\n",
       "1          8.556368        0.003432        8.556613       0.019293\n",
       "2          7.710062        0.003595        7.710767       0.019481\n",
       "3          6.948904        0.003642        6.949960       0.019896\n",
       "4          6.263883        0.003460        6.264859       0.019880\n",
       "5          5.648160        0.003684        5.649071       0.019056\n",
       "6          5.096299        0.003351        5.097878       0.019696\n",
       "7          4.598879        0.003723        4.600709       0.020206\n",
       "8          4.151854        0.003008        4.153995       0.019906\n",
       "9          3.749437        0.002233        3.751680       0.020141\n",
       "10         3.389519        0.002171        3.392068       0.019873\n",
       "11         3.064223        0.002878        3.066381       0.020285\n",
       "12         2.773485        0.003946        2.776073       0.019961\n",
       "13         2.512214        0.003824        2.515039       0.018326\n",
       "14         2.279449        0.002274        2.282171       0.017713\n",
       "15         2.069671        0.002750        2.073251       0.018424\n",
       "16         1.883284        0.003282        1.887193       0.018319\n",
       "17         1.715550        0.005563        1.719684       0.018699\n",
       "18         1.564165        0.005607        1.568890       0.017384\n",
       "19         1.430843        0.005315        1.436255       0.016418\n",
       "20         1.311828        0.006668        1.318105       0.017299\n",
       "21         1.208458        0.007030        1.214859       0.016349\n",
       "22         1.114755        0.008337        1.122041       0.017085\n",
       "23         1.033332        0.009191        1.041271       0.018078\n",
       "24         0.961930        0.010448        0.970798       0.019660\n",
       "25         0.897111        0.012141        0.906443       0.021895\n",
       "26         0.841684        0.013104        0.851702       0.023431\n",
       "27         0.790634        0.012309        0.801245       0.022965\n",
       "28         0.747396        0.011510        0.758697       0.021962\n",
       "29         0.710069        0.011478        0.722497       0.023274\n",
       "30         0.676798        0.010482        0.689679       0.022536\n",
       "31         0.649833        0.011128        0.663249       0.023977\n",
       "32         0.626945        0.011872        0.641061       0.024799\n",
       "33         0.605798        0.012869        0.620460       0.025779\n",
       "34         0.585154        0.011862        0.600607       0.025355\n",
       "35         0.567107        0.011742        0.583331       0.025499\n",
       "36         0.552769        0.009682        0.569542       0.024199\n",
       "37         0.541200        0.008373        0.558353       0.023160\n",
       "38         0.530449        0.009666        0.548227       0.024140\n",
       "39         0.520177        0.010962        0.538169       0.026250\n",
       "40         0.513004        0.011455        0.531504       0.026922\n",
       "41         0.506669        0.011755        0.525638       0.027251\n",
       "42         0.500286        0.011491        0.519747       0.027241\n",
       "43         0.494668        0.010500        0.514585       0.026623\n",
       "44         0.489372        0.011561        0.509709       0.028374\n",
       "45         0.482628        0.011001        0.503237       0.028741\n",
       "46         0.478540        0.009045        0.499483       0.027536\n",
       "47         0.474825        0.006951        0.496148       0.026275\n",
       "48         0.471242        0.006596        0.493428       0.026176\n",
       "49         0.467256        0.005879        0.489847       0.025799"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dmatrix = xgb.DMatrix(data=X_train_data,label=y_train)\n",
    "\n",
    "params = {\"objective\":\"reg:squarederror\",'colsample_bytree': 0.3,'learning_rate': 0.1,\n",
    "                'max_depth': 5, 'alpha': 10}\n",
    "\n",
    "cv_results = xgb.cv(dtrain=data_dmatrix, params=params, nfold=5,\n",
    "                    num_boost_round=50, early_stopping_rounds=10, metrics=\"rmse\", as_pandas=True, seed=123)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HyperParameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "\n",
    "# XGB parameters\n",
    "xgb_reg_params = {\n",
    "#     'learning_rate':    hp.choice('learning_rate',    np.arange(0.05, 0.31, 0.025)),\n",
    "    'max_depth':        hp.choice('max_depth',        np.arange(5, 16, 1, dtype=int)),\n",
    "    'min_child_weight': hp.choice('min_child_weight', np.arange(1, 8, 1, dtype=int)),\n",
    "    'colsample_bytree': hp.choice('colsample_bytree', np.arange(0.5, 1.0, 0.1)),\n",
    "    'subsample':        hp.uniform('subsample', 0.8, 1),\n",
    "    'n_estimators':     hp.choice('n_estimators', np.arange(200, 351, 25)),\n",
    "#     'booster': hp.choice('booster', ['gbtree', 'gblinear', 'dart'])\n",
    "}\n",
    "xgb_fit_params = {\n",
    "    'eval_metric': 'rmse',\n",
    "    'early_stopping_rounds': 10,\n",
    "    'verbose': False\n",
    "}\n",
    "\n",
    "xgb_para = dict()\n",
    "xgb_para['learning_rate'] = 0.075\n",
    "xgb_para['reg_params'] = xgb_reg_params\n",
    "xgb_para['fit_params'] = xgb_fit_params\n",
    "xgb_para['loss_func' ] = lambda y, pred: np.sqrt(mean_squared_error(y, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:50<00:00,  1.97trial/s, best loss: 0.3646194297065025]\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from hyperopt import fmin, tpe, STATUS_OK, STATUS_FAIL, Trials\n",
    "\n",
    "\n",
    "class HPOpt(object):\n",
    "\n",
    "    def __init__(self, x_train, x_test, y_train, y_test):\n",
    "        self.x_train = x_train\n",
    "        self.x_test  = x_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test  = y_test\n",
    "\n",
    "    def process(self, fn_name, space, trials, algo, max_evals):\n",
    "        fn = getattr(self, fn_name)\n",
    "        try:\n",
    "            result = fmin(fn=fn, space=space, algo=algo, max_evals=max_evals, trials=trials)\n",
    "        except Exception as e:\n",
    "            return {'status': STATUS_FAIL,\n",
    "                    'exception': str(e)}\n",
    "        return result, trials\n",
    "\n",
    "    def xgb_reg(self, para):\n",
    "        reg = xgb.XGBRegressor(**para['reg_params'])\n",
    "        return self.train_reg(reg, para)\n",
    "\n",
    "    def lgb_reg(self, para):\n",
    "        reg = lgb.LGBMRegressor(**para['reg_params'])\n",
    "        return self.train_reg(reg, para)\n",
    "\n",
    "    def ctb_reg(self, para):\n",
    "        reg = ctb.CatBoostRegressor(**para['reg_params'])\n",
    "        return self.train_reg(reg, para)\n",
    "\n",
    "    def train_reg(self, reg, para):\n",
    "        reg.fit(self.x_train, self.y_train,\n",
    "                eval_set=[(self.x_train, self.y_train), (self.x_test, self.y_test)],\n",
    "                **para['fit_params'])\n",
    "        pred = reg.predict(self.x_test)\n",
    "        loss = para['loss_func'](self.y_test, pred)\n",
    "        return {'loss': loss, 'status': STATUS_OK}\n",
    "\n",
    "obj = HPOpt(X_train_data, X_test_data, y_train, y_test)\n",
    "\n",
    "xgb_opt = obj.process(fn_name='xgb_reg', space=xgb_para, trials=Trials(), algo=tpe.suggest, max_evals=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "results, trials = xgb_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 1,\n",
       " 'max_depth': 4,\n",
       " 'min_child_weight': 6,\n",
       " 'n_estimators': 2,\n",
       " 'subsample': 0.9639349262264253}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.347687\n"
     ]
    }
   ],
   "source": [
    "xg_reg = xgb.XGBRegressor(objective='reg:squarederror', colsample_bytree=0.7, learning_rate=0.1, \n",
    "                          n_estimators=250, max_depth=12, min_child_weight=4, subsample=0.96)\n",
    "xg_reg.fit(X_train_data, y_train)\n",
    "\n",
    "preds = xg_reg.predict(X_test_data)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "print(\"RMSE: %f\" % (rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
