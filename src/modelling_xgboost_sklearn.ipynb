{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import os, sys\n",
    "\n",
    "# sys.path.append(\"~/X/PythonForDataScience/air_traffic_project/submissions/first_real_submission/\")\n",
    "\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from problem import *\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "import geopy.distance\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from model_selection_python import *\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "\n",
    "from six import StringIO  \n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "import os\n",
    "\n",
    "from estimator_all_features import _merge_external_data\n",
    "# from estimator import _merge_external_data\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Dense,Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.metrics import RootMeanSquaredError\n",
    "\n",
    "from xgboost import XGBRegressor, XGBRFRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = get_train_data('..')\n",
    "X_test, y_test = get_test_data('..')\n",
    "\n",
    "X_train_merged = _merge_external_data(X_train)\n",
    "X_test_merged = _merge_external_data(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_merged.columns[X_train_merged.isna().any()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_to_keep = ['WeeksToDeparture', 'std_wtd', 'Days_to_departure', 'route_mean',\n",
    "#        'n_days_departure', 'day_nb_mean', 'day_mean', 'week_mean',\n",
    "#        'month_mean', 'oil_stock_price', 'oil_stock_volume', 'AAL_stock_price',\n",
    "#        'AAL_stock_volume', 'SP_stock_price', 'SP_stock_volume', 'distance',\n",
    "#        'total_arr', 'flights_arr', 'booth_arr', 'mean_per_flight_arr']\n",
    "\n",
    "# X_train_data = X_train_merged[features_to_keep]\n",
    "# X_test_data = X_test_merged[features_to_keep]\n",
    "\n",
    "X_train_data = X_train_merged\n",
    "X_test_data = X_test_merged\n",
    "\n",
    "X_train_data.drop(['holidays_dep', 'holidays_arr', 'Departure', 'Arrival'], axis=1, inplace=True)\n",
    "X_test_data.drop(['holidays_dep', 'holidays_arr', 'Departure', 'Arrival'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.5, learning_rate = 0.1,\n",
    "               alpha = 10, n_estimators = 100)\n",
    "xg_reg.fit(X_train_data, y_train)\n",
    "\n",
    "preds = xg_reg.predict(X_test_data)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "print(\"RMSE: %f\" % (rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_dmatrix = xgb.DMatrix(data=X_train_data,label=y_train)\n",
    "\n",
    "params = {\"objective\":\"reg:squarederror\",'colsample_bytree': 0.3,'learning_rate': 0.1,\n",
    "                'max_depth': 5, 'alpha': 10}\n",
    "\n",
    "cv_results = xgb.cv(dtrain=data_dmatrix, params=params, nfold=5,\n",
    "                    num_boost_round=50, early_stopping_rounds=10, metrics=\"rmse\", as_pandas=True, seed=123)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HyperParameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "\n",
    "# XGB parameters\n",
    "xgb_reg_params = {\n",
    "    'learning_rate':    hp.choice('learning_rate',    np.arange(0.05, 0.31, 0.025)),\n",
    "    'max_depth':        hp.choice('max_depth',        np.arange(5, 16, 1, dtype=int)),\n",
    "    'min_child_weight': hp.choice('min_child_weight', np.arange(1, 8, 1, dtype=int)),\n",
    "    'colsample_bytree': hp.choice('colsample_bytree', np.arange(0.5, 1.0, 0.1)),\n",
    "    'subsample':        hp.uniform('subsample', 0.8, 1),\n",
    "    'n_estimators':     hp.choice('n_estimators', np.arange(200, 350, 50)),\n",
    "#     'booster': hp.choice('booster', ['gbtree', 'gblinear', 'dart'])\n",
    "}\n",
    "xgb_fit_params = {\n",
    "    'eval_metric': 'rmse',\n",
    "    'early_stopping_rounds': 10,\n",
    "    'verbose': False\n",
    "}\n",
    "\n",
    "xgb_para = dict()\n",
    "# xgb_para['learning_rate'] = 0.075\n",
    "xgb_para['reg_params'] = xgb_reg_params\n",
    "xgb_para['fit_params'] = xgb_fit_params\n",
    "xgb_para['loss_func' ] = lambda y, pred: np.sqrt(mean_squared_error(y, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from hyperopt import fmin, tpe, STATUS_OK, STATUS_FAIL, Trials\n",
    "\n",
    "\n",
    "class HPOpt(object):\n",
    "\n",
    "    def __init__(self, x_train, x_test, y_train, y_test):\n",
    "        self.x_train = x_train\n",
    "        self.x_test  = x_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test  = y_test\n",
    "\n",
    "    def process(self, fn_name, space, trials, algo, max_evals):\n",
    "        fn = getattr(self, fn_name)\n",
    "        try:\n",
    "            result = fmin(fn=fn, space=space, algo=algo, max_evals=max_evals, trials=trials)\n",
    "        except Exception as e:\n",
    "            return {'status': STATUS_FAIL,\n",
    "                    'exception': str(e)}\n",
    "        return result, trials\n",
    "\n",
    "    def xgbrf_reg(self, para):\n",
    "        reg = xgb.XGBRFRegressor(**para['reg_params'])\n",
    "        return self.train_reg(reg, para)\n",
    "    \n",
    "    def xgb_reg(self, para):\n",
    "        reg = xgb.XGBRegressor(**para['reg_params'])\n",
    "        return self.train_reg(reg, para)\n",
    "\n",
    "    def lgb_reg(self, para):\n",
    "        reg = lgb.LGBMRegressor(**para['reg_params'])\n",
    "        return self.train_reg(reg, para)\n",
    "\n",
    "    def ctb_reg(self, para):\n",
    "        reg = ctb.CatBoostRegressor(**para['reg_params'])\n",
    "        return self.train_reg(reg, para)\n",
    "\n",
    "    def train_reg(self, reg, para):\n",
    "        reg.fit(self.x_train, self.y_train,\n",
    "                eval_set=[(self.x_train, self.y_train), (self.x_test, self.y_test)],\n",
    "                **para['fit_params'])\n",
    "        pred = reg.predict(self.x_test)\n",
    "        loss = para['loss_func'](self.y_test, pred)\n",
    "        return {'loss': loss, 'status': STATUS_OK}\n",
    "\n",
    "def power_2(x):\n",
    "    return np.power(x, 2)\n",
    "\n",
    "def inv_fct(x):\n",
    "    return 1/x\n",
    "\n",
    "\n",
    "# Feature Engineering STD_WTD\n",
    "X_train_data['std_wtd_log'] = X_train_data['std_wtd'].transform(np.log)\n",
    "X_train_data['std_wtd_inv'] = X_train_data['std_wtd'].transform(inv_fct)\n",
    "# X_train_data['std_wtd_logsqrt'] = X_train_data['std_wtd_log'].transform(np.sqrt)\n",
    "\n",
    "# X_train_data['std_wtd_log_poly'] = X_train_data['std_wtd'].transform(power_2) + X_train_data['std_wtd']\n",
    "\n",
    "# X_train_data['std_wtd_log10'] = X_train_data['std_wtd'].transform(np.log10)\n",
    "# X_train_data['std_wtd_exp'] = X_train_data['std_wtd'].transform(np.exp)\n",
    "# X_train_data['std_wtd_sqrt'] = X_train_data['std_wtd'].transform(np.sqrt)\n",
    "# X_train_data['std_wtd_power2'] = X_train_data['std_wtd'].transform(power_2)\n",
    "# print(X_train_data.head())\n",
    "\n",
    "X_test_data['std_wtd_log'] = X_test_data['std_wtd'].transform(np.log)\n",
    "X_test_data['std_wtd_inv'] = X_test_data['std_wtd'].transform(inv_fct)\n",
    "\n",
    "obj = HPOpt(X_train_data, X_test_data, y_train, y_test)\n",
    "\n",
    "xgb_opt = obj.process(fn_name='xgb_reg', space=xgb_para, trials=Trials(), algo=tpe.suggest, max_evals=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results, trials = xgb_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     'learning_rate':    hp.choice('learning_rate',    np.arange(0.05, 0.31, 0.025)),\n",
    "#     'max_depth':        hp.choice('max_depth',        np.arange(5, 16, 1, dtype=int)),\n",
    "#     'min_child_weight': hp.choice('min_child_weight', np.arange(1, 8, 1, dtype=int)),\n",
    "#     'colsample_bytree': hp.choice('colsample_bytree', np.arange(0.5, 1.0, 0.1)),\n",
    "#     'subsample':        hp.uniform('subsample', 0.8, 1),\n",
    "#     'n_estimators':     hp.choice('n_estimators', np.arange(5000, 10000, 500)),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obj = HPOpt(X_train_data, X_test_data, y_train, y_test)\n",
    "\n",
    "# xgb_opt = obj.process(fn_name='xgbrf_reg', space=xgb_para, trials=Trials(), algo=tpe.suggest, max_evals=100)\n",
    "# results, trials = xgb_opt\n",
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# X_test_data['std_wtd_logsqrt'] = X_test_data['std_wtd_log'].transform(np.sqrt)\n",
    "\n",
    "# X_test_data['std_wtd_log_poly'] = X_test_data['std_wtd'].transform(power_2) + X_test_data['std_wtd']\n",
    "\n",
    "# X_test_data['std_wtd_log10'] = X_test_data['std_wtd'].transform(np.log10)\n",
    "# X_test_data['std_wtd_exp'] = X_test_data['std_wtd'].transform(np.exp)\n",
    "# X_test_data['std_wtd_sqrt'] = X_test_data['std_wtd'].transform(np.sqrt)\n",
    "# X_test_data['std_wtd_power2'] = X_test_data['std_wtd'].transform(power_2)\n",
    "# print(X_train_data.head())\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective='reg:squarederror', colsample_bytree=0.9, learning_rate=0.05, \n",
    "                          n_estimators=300, max_depth=14, min_child_weight=4, subsample=0.88, booster='gbtree')\n",
    "xg_reg.fit(X_train_data, y_train)\n",
    "\n",
    "preds = xg_reg.predict(X_test_data)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "print(\"RMSE: %f\" % (rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [15, 15]\n",
    "xgb.plot_importance(xg_reg)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RMSE results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "objective='reg:squarederror', colsample_bytree=0.9, learning_rate=0.05, n_estimators=5000, max_depth=13, min_child_weight=3, subsample=0.9527, booster='gbtree' -> RMSE = 0.342055\n",
    "\n",
    "objective='reg:squarederror', colsample_bytree=0.7, learning_rate=0.075, n_estimators=1100, max_depth=13, min_child_weight=6, subsample=0.98, booster='gbtree'-> RMSE = 0.343786\n",
    "\n",
    "RMSE = 250 - 0.347445"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE: 0.347445 - Dart\n",
    "RMSE: 0.345003 - Gbtree"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
