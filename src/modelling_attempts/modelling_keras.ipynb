{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import os, sys\n",
    "\n",
    "# sys.path.append(\"~/X/PythonForDataScience/air_traffic_project/submissions/first_real_submission/\")\n",
    "\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from problem import *\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "import geopy.distance\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from model_selection_python import *\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "\n",
    "from six import StringIO  \n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "import os\n",
    "\n",
    "from estimator_all_features import _merge_external_data\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Dense,Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.metrics import RootMeanSquaredError\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxime/X/PythonForDataScience/air_traffic_project/src/estimator_all_features.py:31: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n",
      "  X_encoded.loc[:, 'week'] = X_encoded['DateOfDeparture'].dt.week\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = get_train_data('..')\n",
    "X_test, y_test = get_test_data('..')\n",
    "\n",
    "X_train_merged = _merge_external_data(X_train)\n",
    "X_test_merged = _merge_external_data(X_test)\n",
    "\n",
    "# features_to_keep = ['WeeksToDeparture', 'week_mean', 'day_mean', 'month_mean', 'day_nb_mean', \n",
    "#                    'route_mean', 'std_wtd', 'n_days_departure']\n",
    "\n",
    "X_train_data = X_train_merged #[features_to_keep]\n",
    "X_test_data = X_test_merged\n",
    "X_train_data.drop(['Departure', 'Arrival', 'holidays_dep', 'holidays_arr'], axis=1, inplace=True) \n",
    "X_test_data.drop(['Departure', 'Arrival', 'holidays_dep', 'holidays_arr'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8902, 77)\n",
      "(2226, 77)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_data.shape)\n",
    "print(X_test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Keras Model\n",
    "# def build_nn():\n",
    "#     # create model\n",
    "#     model= Sequential(\n",
    "#                 [Dense(73,activation='relu',input_shape=[73]),\n",
    "#                  Dense(36,activation='relu'),\n",
    "#                  Dropout(0.2),\n",
    "#                  Dense(18,activation='relu'),\n",
    "#                  Dense(9,activation='relu'),\n",
    "#                  Dense(1)\n",
    "#     ])\n",
    "#     # compile model\n",
    "#     model.compile(optimizer='adam',\n",
    "#               loss='mean_squared_error',\n",
    "#               metrics=['RootMeanSquaredError'])\n",
    "#     return model\n",
    "\n",
    "# # wrap the model using the function you created\n",
    "# keras_reg = KerasRegressor(\n",
    "#                 build_nn,epochs=100,verbose=False)\n",
    "# keras_reg._estimator_type = \"regressor\"\n",
    "\n",
    "# # just create the pipeline\n",
    "# pipeline = Pipeline([\n",
    "#     ('std_scaler', StandardScaler()),\n",
    "#     ('keras_reg',keras_reg)])\n",
    "\n",
    "# pipeline.fit(X_train_data, y_train)\n",
    "# # kfold = KFold(n_splits=10)\n",
    "# # results = cross_val_score(pipeline, X_train_data, y_train, cv=kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Standardized %.2f (%.2f) MSE\" % (results.mean(), results.std()))\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train_pred = pipeline.predict(X_train_data)\n",
    "# y_test_pred = pipeline.predict(X_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train_pred = pipeline.predict(X_train_data)\n",
    "# y_test_pred = pipeline.predict(X_test_data)\n",
    "\n",
    "# score_train = pipeline.score(X_train_data, y_train)\n",
    "# score_test = pipeline.score(X_test_data, y_test)\n",
    "\n",
    "# rmse_train = mean_squared_error(y_train, y_train_pred, squared=False)\n",
    "# rmse_test = mean_squared_error(y_test, y_test_pred, squared=False)\n",
    "\n",
    "# print(f\"Training RMSE: {rmse_train} and Score: {score_train}\")\n",
    "# print(f\"Testing RMSE: {rmse_test} and Score: {score_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(y_test_pred)\n",
    "# print(y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Regression Example With Boston Dataset: Standardized and Wider\n",
    "from pandas import read_csv\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# define wider model\n",
    "def wider_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=77, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "#         model.add(Dense(1, kernel_initializer='normal'))\n",
    "        \n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "# evaluate model with standardized dataset\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=wider_model, epochs=20, batch_size=10, verbose=1)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=5)\n",
    "results = cross_val_score(pipeline, X_train_data, y_train, cv=kfold)\n",
    "print(\"Wider: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define wider model\n",
    "def wider_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=77, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "#         model.add(Dense(1, kernel_initializer='normal'))\n",
    "        \n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=wider_model, epochs=20, batch_size=10, verbose=1)))\n",
    "pipeline = Pipeline(estimators)\n",
    "# kfold = KFold(n_splits=5)\n",
    "\n",
    "pipeline.fit(X_train_data, y_train)\n",
    "y_train_pred = pipeline.predict(X_train_data)\n",
    "y_test_pred = pipeline.predict(X_test_data)\n",
    "\n",
    "score_train = pipeline.score(X_train_data, y_train)\n",
    "score_test = pipeline.score(X_test_data, y_test)\n",
    "\n",
    "rmse_train = mean_squared_error(y_train, y_train_pred, squared=False)\n",
    "rmse_test = mean_squared_error(y_test, y_test_pred, squared=False)\n",
    "\n",
    "print(f\"Training RMSE: {rmse_train} and Score: {score_train}\")\n",
    "print(f\"Testing RMSE: {rmse_test} and Score: {score_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
