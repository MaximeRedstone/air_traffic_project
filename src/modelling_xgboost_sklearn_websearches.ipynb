{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import os, sys\n",
    "\n",
    "# sys.path.append(\"~/X/PythonForDataScience/air_traffic_project/submissions/first_real_submission/\")\n",
    "\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from problem import *\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "import geopy.distance\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from model_selection_python import *\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "\n",
    "from six import StringIO  \n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "import os\n",
    "\n",
    "from estimator_web_searches import _merge_external_data\n",
    "# from estimator_all_features import _merge_external_data\n",
    "# from estimator import _merge_external_data\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Dense,Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.metrics import RootMeanSquaredError\n",
    "\n",
    "from xgboost import XGBRegressor, XGBRFRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from hyperopt import fmin, tpe, STATUS_OK, STATUS_FAIL, Trials\n",
    "\n",
    "\n",
    "class HPOpt(object):\n",
    "\n",
    "    def __init__(self, x_train, x_test, y_train, y_test):\n",
    "        self.x_train = x_train\n",
    "        self.x_test  = x_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test  = y_test\n",
    "\n",
    "    def process(self, fn_name, space, trials, algo, max_evals):\n",
    "        fn = getattr(self, fn_name)\n",
    "        try:\n",
    "            result = fmin(fn=fn, space=space, algo=algo, max_evals=max_evals, trials=trials)\n",
    "        except Exception as e:\n",
    "            return {'status': STATUS_FAIL,\n",
    "                    'exception': str(e)}\n",
    "        return result, trials\n",
    "\n",
    "    def xgbrf_reg(self, para):\n",
    "        reg = xgb.XGBRFRegressor(**para['reg_params'])\n",
    "        return self.train_reg(reg, para)\n",
    "    \n",
    "    def xgb_reg(self, para):\n",
    "        reg = xgb.XGBRegressor(**para['reg_params'])\n",
    "        return self.train_reg(reg, para)\n",
    "\n",
    "    def lgb_reg(self, para):\n",
    "        reg = lgb.LGBMRegressor(**para['reg_params'])\n",
    "        return self.train_reg(reg, para)\n",
    "\n",
    "    def ctb_reg(self, para):\n",
    "        reg = ctb.CatBoostRegressor(**para['reg_params'])\n",
    "        return self.train_reg(reg, para)\n",
    "\n",
    "    def train_reg(self, reg, para):\n",
    "        reg.fit(self.x_train, self.y_train,\n",
    "                eval_set=[(self.x_train, self.y_train), (self.x_test, self.y_test)],\n",
    "                **para['fit_params'])\n",
    "        pred = reg.predict(self.x_test)\n",
    "        loss = para['loss_func'](self.y_test, pred)\n",
    "        return {'loss': loss, 'status': STATUS_OK}\n",
    "\n",
    "def power_2(x):\n",
    "    return np.power(x, 2)\n",
    "\n",
    "def inv_fct(x):\n",
    "    return 1/x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8902, 5)\n",
      "after first merge (9226, 21)\n",
      "After second merge:  (10510, 54)\n",
      "After second merge:  (15622, 85)\n",
      "After second merge:  (15622, 86)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxime/X/PythonForDataScience/air_traffic_project/src/estimator_web_searches.py:31: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n",
      "  X_encoded.loc[:, 'week'] = X_encoded['DateOfDeparture'].dt.week\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after first merge (2324, 21)\n",
      "After second merge:  (2712, 54)\n",
      "After second merge:  (4256, 85)\n",
      "After second merge:  (4256, 86)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = get_train_data('..')\n",
    "print(X_train.shape)\n",
    "\n",
    "X_test, y_test = get_test_data('..')\n",
    "\n",
    "X_train_merged = _merge_external_data(X_train)\n",
    "X_test_merged = _merge_external_data(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['WeeksToDeparture', 'std_wtd', 'Days_to_departure', 'route_mean',\n",
       "       'year_departure', 'day_departure', 'n_days_departure', 'day_nb_mean',\n",
       "       'day_mean', 'week_mean', 'month_mean', 'oil_stock_price',\n",
       "       'oil_stock_volume', 'AAL_stock_price', 'AAL_stock_volume',\n",
       "       'SP_stock_price', 'SP_stock_volume', 'Max TemperatureC_dep',\n",
       "       'Mean TemperatureC_dep', 'Min TemperatureC_dep', 'Dew PointC_dep',\n",
       "       'MeanDew PointC_dep', 'Min DewpointC_dep', 'Max Humidity_dep',\n",
       "       'Mean Humidity_dep', 'Min Humidity_dep',\n",
       "       'Max Sea Level PressurehPa_dep', 'Mean Sea Level PressurehPa_dep',\n",
       "       'Min Sea Level PressurehPa_dep', 'Max VisibilityKm_dep',\n",
       "       'Mean VisibilityKm_dep', 'Min VisibilitykM_dep',\n",
       "       'Max Wind SpeedKm/h_dep', 'Mean Wind SpeedKm/h_dep', 'CloudCover_dep',\n",
       "       'WindDirDegrees_dep', 'LoadFactorDomestic_dep',\n",
       "       'PassengersDomestic_dep', 'latitude_deg_dep', 'longitude_deg_dep',\n",
       "       'pop2010_dep', 'UnemploymentRate_dep', 'GDP_per_cap_dep',\n",
       "       'closest_holidays_dep', 'total_arr', 'flights_arr', 'booth_arr',\n",
       "       'mean_per_flight_arr', 'Max TemperatureC_arr', 'Mean TemperatureC_arr',\n",
       "       'Min TemperatureC_arr', 'Dew PointC_arr', 'MeanDew PointC_arr',\n",
       "       'Min DewpointC_arr', 'Max Humidity_arr', 'Mean Humidity_arr',\n",
       "       'Min Humidity_arr', 'Max Sea Level PressurehPa_arr',\n",
       "       'Mean Sea Level PressurehPa_arr', 'Min Sea Level PressurehPa_arr',\n",
       "       'Max VisibilityKm_arr', 'Mean VisibilityKm_arr', 'Min VisibilitykM_arr',\n",
       "       'Max Wind SpeedKm/h_arr', 'Mean Wind SpeedKm/h_arr', 'CloudCover_arr',\n",
       "       'WindDirDegrees_arr', 'LoadFactorDomestic_arr',\n",
       "       'PassengersDomestic_arr', 'latitude_deg_arr', 'longitude_deg_arr',\n",
       "       'pop2010_arr', 'UnemploymentRate_arr', 'GDP_per_cap_arr',\n",
       "       'closest_holidays_arr', 'search_intensity_datedep_arr',\n",
       "       'search_intensity_datedep_arr', 'distance', 'day_nb'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_merged.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_merged.columns[X_train_merged.isna().any()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15622, 79)\n",
      "(4256, 79)\n"
     ]
    }
   ],
   "source": [
    "X_train_data = X_train_merged\n",
    "X_test_data = X_test_merged\n",
    "\n",
    "print(X_train_data.shape)\n",
    "print(X_test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "\n",
    "# XGB parameters\n",
    "xgb_reg_params = {\n",
    "    'learning_rate':    hp.choice('learning_rate',    np.arange(0.01, 0.31, 0.005)),\n",
    "    'max_depth':        hp.choice('max_depth',        np.arange(5, 16, 1, dtype=int)),\n",
    "    'min_child_weight': hp.choice('min_child_weight', np.arange(1, 8, 1, dtype=int)),\n",
    "    'colsample_bytree': hp.choice('colsample_bytree', np.arange(0.5, 1.0, 0.1)),\n",
    "    'subsample':        hp.uniform('subsample', 0.8, 1),\n",
    "    'n_estimators':     hp.choice('n_estimators', np.arange(5000, 10000, 1000)),\n",
    "}\n",
    "xgb_fit_params = {\n",
    "    'eval_metric': 'rmse',\n",
    "    'early_stopping_rounds': 10,\n",
    "    'verbose': False\n",
    "}\n",
    "\n",
    "xgb_para = dict()\n",
    "xgb_para['reg_params'] = xgb_reg_params\n",
    "xgb_para['fit_params'] = xgb_fit_params\n",
    "xgb_para['loss_func' ] = lambda y, pred: np.sqrt(mean_squared_error(y, pred))\n",
    "\n",
    "# Feature Engineering STD_WTD\n",
    "X_train_data['std_wtd_log'] = X_train_data['std_wtd'].transform(np.log)\n",
    "X_train_data['std_wtd_inv'] = X_train_data['std_wtd'].transform(inv_fct)\n",
    "\n",
    "X_test_data['std_wtd_log'] = X_test_data['std_wtd'].transform(np.log)\n",
    "X_test_data['std_wtd_inv'] = X_test_data['std_wtd'].transform(inv_fct)\n",
    "\n",
    "obj = HPOpt(X_train_data, X_test_data, y_train, y_test)\n",
    "\n",
    "xgb_opt = obj.process(fn_name='xgb_reg', space=xgb_para, trials=Trials(), algo=tpe.suggest, max_evals=100)\n",
    "\n",
    "results, trials = xgb_opt\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing on one XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " xg_reg = xgb.XGBRegressor(objective='reg:squarederror', colsample_bytree=0.6, learning_rate=0.02, \n",
    "                          n_estimators=9000, max_depth=9, min_child_weight=5, subsample=0.98, \n",
    "                          booster='gbtree')\n",
    "\n",
    "xg_reg.fit(X_train_data, y_train)\n",
    "\n",
    "preds = xg_reg.predict(X_test_data)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "print(\"RMSE: %f\" % (rmse))\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [15, 15]\n",
    "xgb.plot_importance(xg_reg)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
