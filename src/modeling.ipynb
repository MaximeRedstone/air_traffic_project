{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import os\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import problem\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "import geopy.distance\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from model_selection_python import *\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_problem_data(get_dummies=True):\n",
    "    \n",
    "    X_train = pd.read_csv('../data/X_train.csv')\n",
    "    X_test = pd.read_csv('../data/X_test.csv')\n",
    "    y_train = pd.read_csv('../data/y_train.csv')\n",
    "    y_test = pd.read_csv('../data/y_test.csv')\n",
    "    \n",
    "    if get_dummies:\n",
    "        X_train = pd.get_dummies(X_train, drop_first=True)\n",
    "        X_test = pd.get_dummies(X_test, drop_first=True)\n",
    "   \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train =  (8902, 72)\n",
      "y_train =  (8902, 1)\n",
      "X_test =  (2226, 72)\n",
      "y_test =  (2226, 1)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8902 entries, 0 to 8901\n",
      "Data columns (total 72 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   WeeksToDeparture              8902 non-null   float64\n",
      " 1   std_wtd                       8902 non-null   float64\n",
      " 2   oil_stock_price               8902 non-null   float64\n",
      " 3   oil_stock_volume              8902 non-null   float64\n",
      " 4   AAL_stock_price               8902 non-null   float64\n",
      " 5   AAL_stock_volume              8902 non-null   float64\n",
      " 6   SP_stock_price                8902 non-null   float64\n",
      " 7   SP_stock_volume               8902 non-null   float64\n",
      " 8   latitude_departure            8902 non-null   float64\n",
      " 9   longitude_departure           8902 non-null   float64\n",
      " 10  population_departure          8902 non-null   float64\n",
      " 11  latitude_arrival              8902 non-null   float64\n",
      " 12  longitude_arrival             8902 non-null   float64\n",
      " 13  population_arrival            8902 non-null   float64\n",
      " 14  distance                      8902 non-null   float64\n",
      " 15  Max TemperatureC_x            8902 non-null   int64  \n",
      " 16  Mean TemperatureC_x           8902 non-null   int64  \n",
      " 17  Min TemperatureC_x            8902 non-null   int64  \n",
      " 18  Dew PointC_x                  8902 non-null   int64  \n",
      " 19  MeanDew PointC_x              8902 non-null   int64  \n",
      " 20  Min DewpointC_x               8902 non-null   int64  \n",
      " 21  Max Humidity_x                8902 non-null   int64  \n",
      " 22  Mean Humidity_x               8902 non-null   int64  \n",
      " 23  Min Humidity_x                8902 non-null   int64  \n",
      " 24  Max Sea Level PressurehPa_x   8902 non-null   int64  \n",
      " 25  Mean Sea Level PressurehPa_x  8902 non-null   int64  \n",
      " 26  Min Sea Level PressurehPa_x   8902 non-null   int64  \n",
      " 27  Max VisibilityKm_x            8902 non-null   int64  \n",
      " 28  Mean VisibilityKm_x           8902 non-null   int64  \n",
      " 29  Min VisibilitykM_x            8902 non-null   int64  \n",
      " 30  Max Wind SpeedKm/h_x          8902 non-null   int64  \n",
      " 31  Mean Wind SpeedKm/h_x         8902 non-null   int64  \n",
      " 32  CloudCover_x                  8902 non-null   int64  \n",
      " 33  WindDirDegrees_x              8902 non-null   int64  \n",
      " 34  LoadFactorDomestic_x          8902 non-null   float64\n",
      " 35  PassengersDomestic_x          8902 non-null   int64  \n",
      " 36  Max TemperatureC_y            8902 non-null   int64  \n",
      " 37  Mean TemperatureC_y           8902 non-null   int64  \n",
      " 38  Min TemperatureC_y            8902 non-null   int64  \n",
      " 39  Dew PointC_y                  8902 non-null   int64  \n",
      " 40  MeanDew PointC_y              8902 non-null   int64  \n",
      " 41  Min DewpointC_y               8902 non-null   int64  \n",
      " 42  Max Humidity_y                8902 non-null   int64  \n",
      " 43  Mean Humidity_y               8902 non-null   int64  \n",
      " 44  Min Humidity_y                8902 non-null   int64  \n",
      " 45  Max Sea Level PressurehPa_y   8902 non-null   int64  \n",
      " 46  Mean Sea Level PressurehPa_y  8902 non-null   int64  \n",
      " 47  Min Sea Level PressurehPa_y   8902 non-null   int64  \n",
      " 48  Max VisibilityKm_y            8902 non-null   int64  \n",
      " 49  Mean VisibilityKm_y           8902 non-null   int64  \n",
      " 50  Min VisibilitykM_y            8902 non-null   int64  \n",
      " 51  Max Wind SpeedKm/h_y          8902 non-null   int64  \n",
      " 52  Mean Wind SpeedKm/h_y         8902 non-null   int64  \n",
      " 53  CloudCover_y                  8902 non-null   int64  \n",
      " 54  WindDirDegrees_y              8902 non-null   int64  \n",
      " 55  LoadFactorDomestic_y          8902 non-null   float64\n",
      " 56  PassengersDomestic_y          8902 non-null   int64  \n",
      " 57  holidays                      8902 non-null   bool   \n",
      " 58  GDP_per_cap                   8902 non-null   float64\n",
      " 59  UnemploymentRateBooked        8902 non-null   float64\n",
      " 60  year_departure                8902 non-null   int64  \n",
      " 61  month_departure               8902 non-null   int64  \n",
      " 62  day_departure                 8902 non-null   int64  \n",
      " 63  weekday_departure             8902 non-null   int64  \n",
      " 64  week_departure                8902 non-null   int64  \n",
      " 65  n_days_departure              8902 non-null   int64  \n",
      " 66  year_booked                   8902 non-null   int64  \n",
      " 67  month_booked                  8902 non-null   int64  \n",
      " 68  day_booked                    8902 non-null   int64  \n",
      " 69  weekday_booked                8902 non-null   int64  \n",
      " 70  week_booked                   8902 non-null   int64  \n",
      " 71  n_days_booked                 8902 non-null   int64  \n",
      "dtypes: bool(1), float64(19), int64(52)\n",
      "memory usage: 4.8 MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8902 entries, 0 to 8901\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       8902 non-null   float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 69.7 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = get_problem_data(get_dummies=True)\n",
    "print(\"X_train = \", X_train.shape)\n",
    "print(\"y_train = \", y_train.shape)\n",
    "print(\"X_test = \", X_test.shape)\n",
    "print(\"y_test = \", y_test.shape)\n",
    "\n",
    "print(X_train.info())\n",
    "print(y_train.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    errors = abs(predictions - test_labels)\n",
    "    mape = 100 * np.mean(errors / test_labels)\n",
    "    accuracy = 100 - mape\n",
    "    print('Model Performance')\n",
    "    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
    "    print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_forest = X_train[['std_wtd', 'WeeksToDeparture', 'oil_stock_price', 'oil_stock_volume',\n",
    "                    'AAL_stock_price', 'AAL_stock_volume', 'SP_stock_price', 'SP_stock_volume',\n",
    "                    'latitude_departure', 'longitude_departure', 'population_departure', \n",
    "                    'latitude_arrival', 'longitude_arrival', 'population_arrival', 'distance',\n",
    "                    'LoadFactorDomestic_y', 'PassengersDomestic_y', 'holidays', 'GDP_per_cap',\n",
    "                    'UnemploymentRateBooked', 'year_departure', 'month_departure', 'day_departure', \n",
    "                    'weekday_departure', 'week_departure', 'n_days_departure', 'year_booked', \n",
    "                    'month_booked', 'day_booked', 'weekday_booked', 'week_booked', 'n_days_booked']]\n",
    "\n",
    "\n",
    "# forest = RandomForestRegressor(min_samples_split=0.01, max_features=0.5, oob_score=True, verbose=0)\n",
    "# score = cross_val_score(forest, X_forest, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Hugo/anaconda3/envs/airvenv/lib/python3.8/site-packages/sklearn/model_selection/_search.py:765: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7307415817201812\n"
     ]
    }
   ],
   "source": [
    "grid_params = {\n",
    "    'min_samples_split': [0.01],\n",
    "    'max_features': [0.5]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(estimator=RandomForestRegressor(),\n",
    "                  param_grid=grid_params,\n",
    "                  n_jobs=-1,\n",
    "                  cv=5,\n",
    "                  verbose=0)\n",
    "\n",
    "gs.fit(X_forest, y_train)        \n",
    "print(gs.best_score_)                                                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6860441381908837\n"
     ]
    }
   ],
   "source": [
    "# Prediction performance on test set is not as good as on train set\n",
    "score_test = gs.score(X_test[['std_wtd', 'WeeksToDeparture', 'oil_stock_price', 'oil_stock_volume',\n",
    "                    'AAL_stock_price', 'AAL_stock_volume', 'SP_stock_price', 'SP_stock_volume',\n",
    "                    'latitude_departure', 'longitude_departure', 'population_departure', \n",
    "                    'latitude_arrival', 'longitude_arrival', 'population_arrival', 'distance',\n",
    "                    'LoadFactorDomestic_y', 'PassengersDomestic_y', 'holidays', 'GDP_per_cap',\n",
    "                    'UnemploymentRateBooked', 'year_departure', 'month_departure', 'day_departure', \n",
    "                    'weekday_departure', 'week_departure', 'n_days_departure', 'year_booked', \n",
    "                    'month_booked', 'day_booked', 'weekday_booked', 'week_booked', 'n_days_booked']], y_test)\n",
    "\n",
    "print(score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(30, 30))\n",
    "# sns.heatmap(abs(Xy_train.corr()), cmap='BrBG', annot=True, vmin=-1, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(8, 15))\n",
    "# heatmap = sns.heatmap(Xy_train.corr()[['Passengers']].sort_values(by='Passengers', ascending=False), vmin=-1, vmax=1, annot=True, cmap='BrBG')\n",
    "# heatmap.set_title('Features Correlating with Sales Price', fontdict={'fontsize':18}, pad=16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# grid_params = {\n",
    "#     'n_neighbors': range(1, 200),\n",
    "#     'weights': ['uniform', 'distance'],\n",
    "#     'metric': ['euclidean', 'manhattan'],\n",
    "# }\n",
    "\n",
    "# gs = GridSearchCV(\n",
    "#     KNeighborsRegressor(),\n",
    "#     grid_params,\n",
    "#     verbose=1,\n",
    "#     cv=3,\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "\n",
    "# gs_results = gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(gs_results.best_score_)\n",
    "# print(gs_results.best_estimator_)\n",
    "# print(gs_results.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, y_train = problem.get_train_data('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-70eb69285773>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m gs = GridSearchCV(\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mpipe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mgrid_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pipe' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "grid_params = {\n",
    "    'randomforestregressor__n_estimators': [50, 100],\n",
    "    'randomforestregressor__max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'randomforestregressor__max_depth': [4, 6, 8],\n",
    "    'randomforestregressor__criterion': ['mse']\n",
    "}\n",
    "\n",
    "# pipe = make_pipeline(StandardScaler(with_mean=False), RandomForestRegressor())\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    pipe,\n",
    "    grid_params,\n",
    "    verbose=1,\n",
    "    cv=3,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "gs_results = gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gs_results.best_score_)\n",
    "print(gs_results.best_estimator_)\n",
    "print(gs_results.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.inspection import permutation_importance\n",
    "\n",
    "# feature_importances = permutation_importance(\n",
    "#     pipe, X_train, y_train, n_repeats=10\n",
    "# )\n",
    "# sorted_idx = feature_importances.importances_mean.argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(15, 15))\n",
    "# ax.boxplot(feature_importances.importances[sorted_idx].T,\n",
    "#            vert=False, labels=X_train.columns[sorted_idx])\n",
    "# ax.set_title(\"Permutation Importances (train set)\")\n",
    "# fig.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_importances = permutation_importance(\n",
    "#     pipe, X_test, y_test, n_repeats=10\n",
    "# )\n",
    "# sorted_idx = feature_importances.importances_mean.argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(15, 15))\n",
    "# ax.boxplot(feature_importances.importances[sorted_idx].T,\n",
    "#            vert=False, labels=X_test.columns[sorted_idx])\n",
    "# ax.set_title(\"Permutation Importances (test set)\")\n",
    "# fig.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictor Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train = sm.add_constant(X_train)\n",
    "print(X_train.info())\n",
    "print(\"X as array:\", np.asarray(X_train))\n",
    "print(\"y as array:\", np.asarray(y_train))\n",
    "model_both = forwardSelection(X_train.astype(float), y_train.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pca(data, index, n_components=2):\n",
    "    \"\"\" Plot the PCA transformation of Sklearn module\n",
    "\n",
    "    Args:\n",
    "        data (np.array): Original scaled data as numpy array \n",
    "                         (n samples, d features)\n",
    "        index (list): list of strings to label samples\n",
    "        n_components (int, optional): Number of Principal Components to keep. \n",
    "                                      Defaults to 2.\n",
    "    \"\"\"\n",
    "\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca_data = pca.fit_transform(data)\n",
    "    per_var = np.round(pca.explained_variance_ratio_ * 100, decimals=1)\n",
    "\n",
    "    labels = []\n",
    "    for i in range(len(per_var)):\n",
    "        labels.append('PC' + str(i + 1) + \" : \" + str(per_var[i]))\n",
    "\n",
    "    pca_df = pd.DataFrame(pca_data, index=index, columns=labels)\n",
    "\n",
    "    if n_components == 2:\n",
    "        plt.scatter(pca_df[labels[0]], pca_df[labels[1]], alpha=0.1)\n",
    "        plt.xlabel(labels[0])\n",
    "        plt.ylabel(labels[1])\n",
    "#         for sample in pca_df.index:\n",
    "#             plt.annotate(sample, (pca_df.loc[sample, labels[0]], pca_df.loc[sample, labels[1]]), rotation=45)\n",
    "    \n",
    "    elif n_components == 3:\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        X = pca_df[labels[0]]\n",
    "        Y = pca_df[labels[1]]\n",
    "        Z = pca_df[labels[2]]\n",
    "        ax.scatter(X, Y, Z)\n",
    "        ax.set_xlabel(labels[0], labelpad=20)\n",
    "        ax.set_ylabel(labels[1], labelpad=20)\n",
    "        ax.set_zlabel(labels[2], labelpad=20)\n",
    "        for sample in pca_df.index:\n",
    "            ax.text(pca_df.loc[sample, labels[0]], pca_df.loc[sample, labels[1]], pca_df.loc[sample, labels[2]],\n",
    "                    '%s' % sample, size=20, color='k', rotation=50) \n",
    "    plt.title(\"Data projected on space given by the {} principal components.\".format(n_components))\n",
    "    plt.show()\n",
    "    \n",
    "    plt.hist(per_var)\n",
    "    plt.show()\n",
    "        \n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "scaled_X_train_np = scaler.transform(X_train)\n",
    "scaled_X_train_df = pd.DataFrame(scaled_X_train_np, index=X_train.index, columns=X_train.columns)\n",
    "# scaled_consumption_df \n",
    "\n",
    "pca = PCA(n_components=25)\n",
    "pca_data = pca.fit_transform(scaled_X_train_np)\n",
    "per_var = np.round(pca.explained_variance_ratio_ * 100, decimals=1)\n",
    "print(per_var)\n",
    "print(sum(per_var))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "pipe = make_pipeline(OneHotEncoder(handle_unknown='ignore'),\n",
    "                    StandardScaler(with_mean=False),\n",
    "                    LinearRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X_train, y_train)\n",
    "y_train_pred = pipe.predict(X_train)\n",
    "#print(\"10 first y_train pred = \", y_train_pred[:10])\n",
    "#print(\"10 first y_train = \", y_train[:10])\n",
    "print(\"Score on train set = \", pipe.score(X_train, y_train))\n",
    "\n",
    "mean_error_train = mean_squared_error(y_train, y_train_pred)\n",
    "print(\"Mean square error = \", mean_error_train)\n",
    "\n",
    "y_test_pred = pipe.predict(X_test)\n",
    "#print(\"10 first y_test pred = \", y_test_pred[:10])\n",
    "#print(\"10 first y_test = \", y_test[:10])\n",
    "print(\"Score on test set = \", pipe.score(X_test, y_test))\n",
    "\n",
    "mean_error_test = mean_squared_error(y_test, y_test_pred)\n",
    "print(\"Mean square error = \", mean_error_test)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
