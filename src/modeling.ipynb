{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import os\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import problem\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "import geopy.distance\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from model_selection_python import *\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_problem_data(get_dummies=True):\n",
    "    \n",
    "    X_train = pd.read_csv('../data/X_train.csv')\n",
    "    X_test = pd.read_csv('../data/X_test.csv')\n",
    "    y_train = pd.read_csv('../data/y_train.csv')\n",
    "    y_test = pd.read_csv('../data/y_test.csv')\n",
    "    \n",
    "#     X_train.loc[:, 'DateOfDeparture'] = pd.to_datetime(X_train.loc[:, 'DateOfDeparture'])\n",
    "#     X_test.loc[:, 'DateOfDeparture'] = pd.to_datetime(X_test.loc[:, 'DateOfDeparture'])\n",
    "    \n",
    "    X_train.drop(['DateOfDeparture', 'state_arrival', 'state_departure'], axis=1, inplace=True)\n",
    "    X_test.drop(['DateOfDeparture', 'state_arrival', 'state_departure'], axis=1, inplace=True)\n",
    "    \n",
    "    if get_dummies:\n",
    "        X_train = pd.get_dummies(X_train, drop_first=True)\n",
    "        X_test = pd.get_dummies(X_test, drop_first=True)\n",
    "   \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = get_problem_data(get_dummies=False)\n",
    "print(\"X_train = \", X_train.shape)\n",
    "print(\"y_train = \", y_train.shape)\n",
    "print(\"X_test = \", X_test.shape)\n",
    "print(\"y_test = \", y_test.shape)\n",
    "\n",
    "print(X_train.info())\n",
    "print(y_train.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy_train = X_train.copy()\n",
    "Xy_train['Passengers'] = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_train, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30, 30))\n",
    "sns.heatmap(abs(Xy_train.corr()), cmap='BrBG', annot=True, vmin=-1, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 15))\n",
    "heatmap = sns.heatmap(Xy_train.corr()[['Passengers']].sort_values(by='Passengers', ascending=False), vmin=-1, vmax=1, annot=True, cmap='BrBG')\n",
    "heatmap.set_title('Features Correlating with Sales Price', fontdict={'fontsize':18}, pad=16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "grid_params = {\n",
    "    'n_neighbors': range(1, 200),\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan'],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    KNeighborsRegressor(),\n",
    "    grid_params,\n",
    "    verbose=1,\n",
    "    cv=3,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "gs_results = gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gs_results.best_score_)\n",
    "print(gs_results.best_estimator_)\n",
    "print(gs_results.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, y_train = problem.get_train_data('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "grid_params = {\n",
    "    'randomforestregressor__n_estimators': [50, 100],\n",
    "    'randomforestregressor__max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'randomforestregressor__max_depth': [4, 6, 8],\n",
    "    'randomforestregressor__criterion': ['mse']\n",
    "}\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(with_mean=False), RandomForestRegressor())\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    pipe,\n",
    "    grid_params,\n",
    "    verbose=1,\n",
    "    cv=3,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "gs_results = gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gs_results.best_score_)\n",
    "print(gs_results.best_estimator_)\n",
    "print(gs_results.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.inspection import permutation_importance\n",
    "\n",
    "# feature_importances = permutation_importance(\n",
    "#     pipe, X_train, y_train, n_repeats=10\n",
    "# )\n",
    "# sorted_idx = feature_importances.importances_mean.argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(15, 15))\n",
    "# ax.boxplot(feature_importances.importances[sorted_idx].T,\n",
    "#            vert=False, labels=X_train.columns[sorted_idx])\n",
    "# ax.set_title(\"Permutation Importances (train set)\")\n",
    "# fig.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_importances = permutation_importance(\n",
    "#     pipe, X_test, y_test, n_repeats=10\n",
    "# )\n",
    "# sorted_idx = feature_importances.importances_mean.argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(15, 15))\n",
    "# ax.boxplot(feature_importances.importances[sorted_idx].T,\n",
    "#            vert=False, labels=X_test.columns[sorted_idx])\n",
    "# ax.set_title(\"Permutation Importances (test set)\")\n",
    "# fig.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictor Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train = sm.add_constant(X_train)\n",
    "print(X_train.info())\n",
    "print(\"X as array:\", np.asarray(X_train))\n",
    "print(\"y as array:\", np.asarray(y_train))\n",
    "model_both = forwardSelection(X_train.astype(float), y_train.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pca(data, index, n_components=2):\n",
    "    \"\"\" Plot the PCA transformation of Sklearn module\n",
    "\n",
    "    Args:\n",
    "        data (np.array): Original scaled data as numpy array \n",
    "                         (n samples, d features)\n",
    "        index (list): list of strings to label samples\n",
    "        n_components (int, optional): Number of Principal Components to keep. \n",
    "                                      Defaults to 2.\n",
    "    \"\"\"\n",
    "\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca_data = pca.fit_transform(data)\n",
    "    per_var = np.round(pca.explained_variance_ratio_ * 100, decimals=1)\n",
    "\n",
    "    labels = []\n",
    "    for i in range(len(per_var)):\n",
    "        labels.append('PC' + str(i + 1) + \" : \" + str(per_var[i]))\n",
    "\n",
    "    pca_df = pd.DataFrame(pca_data, index=index, columns=labels)\n",
    "\n",
    "    if n_components == 2:\n",
    "        plt.scatter(pca_df[labels[0]], pca_df[labels[1]], alpha=0.1)\n",
    "        plt.xlabel(labels[0])\n",
    "        plt.ylabel(labels[1])\n",
    "#         for sample in pca_df.index:\n",
    "#             plt.annotate(sample, (pca_df.loc[sample, labels[0]], pca_df.loc[sample, labels[1]]), rotation=45)\n",
    "    \n",
    "    elif n_components == 3:\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        X = pca_df[labels[0]]\n",
    "        Y = pca_df[labels[1]]\n",
    "        Z = pca_df[labels[2]]\n",
    "        ax.scatter(X, Y, Z)\n",
    "        ax.set_xlabel(labels[0], labelpad=20)\n",
    "        ax.set_ylabel(labels[1], labelpad=20)\n",
    "        ax.set_zlabel(labels[2], labelpad=20)\n",
    "        for sample in pca_df.index:\n",
    "            ax.text(pca_df.loc[sample, labels[0]], pca_df.loc[sample, labels[1]], pca_df.loc[sample, labels[2]],\n",
    "                    '%s' % sample, size=20, color='k', rotation=50) \n",
    "    plt.title(\"Data projected on space given by the {} principal components.\".format(n_components))\n",
    "    plt.show()\n",
    "    \n",
    "    plt.hist(per_var)\n",
    "    plt.show()\n",
    "        \n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "scaled_X_train_np = scaler.transform(X_train)\n",
    "scaled_X_train_df = pd.DataFrame(scaled_X_train_np, index=X_train.index, columns=X_train.columns)\n",
    "# scaled_consumption_df \n",
    "\n",
    "pca = PCA(n_components=25)\n",
    "pca_data = pca.fit_transform(scaled_X_train_np)\n",
    "per_var = np.round(pca.explained_variance_ratio_ * 100, decimals=1)\n",
    "print(per_var)\n",
    "print(sum(per_var))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "pipe = make_pipeline(OneHotEncoder(handle_unknown='ignore'),\n",
    "                    StandardScaler(with_mean=False),\n",
    "                    LinearRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X_train, y_train)\n",
    "y_train_pred = pipe.predict(X_train)\n",
    "#print(\"10 first y_train pred = \", y_train_pred[:10])\n",
    "#print(\"10 first y_train = \", y_train[:10])\n",
    "print(\"Score on train set = \", pipe.score(X_train, y_train))\n",
    "\n",
    "mean_error_train = mean_squared_error(y_train, y_train_pred)\n",
    "print(\"Mean square error = \", mean_error_train)\n",
    "\n",
    "y_test_pred = pipe.predict(X_test)\n",
    "#print(\"10 first y_test pred = \", y_test_pred[:10])\n",
    "#print(\"10 first y_test = \", y_test[:10])\n",
    "print(\"Score on test set = \", pipe.score(X_test, y_test))\n",
    "\n",
    "mean_error_test = mean_squared_error(y_test, y_test_pred)\n",
    "print(\"Mean square error = \", mean_error_test)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
