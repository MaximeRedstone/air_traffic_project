{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import os, sys\n",
    "\n",
    "# sys.path.append(\"~/X/PythonForDataScience/air_traffic_project/submissions/first_real_submission/\")\n",
    "\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from problem import *\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "import geopy.distance\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from model_selection_python import *\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "\n",
    "from six import StringIO  \n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "import os\n",
    "\n",
    "from estimator import _merge_external_data\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Dense,Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.metrics import RootMeanSquaredError\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Hugo/Desktop/X-HEC/Polytechnique/Semestre 1/Python_For_Data_Science/air_traffic_project/src/external_data.csv\n",
      "/Users/Hugo/Desktop/X-HEC/Polytechnique/Semestre 1/Python_For_Data_Science/air_traffic_project/src/external_data.csv\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = get_train_data('..')\n",
    "X_test, y_test = get_test_data('..')\n",
    "\n",
    "X_train_merged = _merge_external_data(X_train)\n",
    "X_test_merged = _merge_external_data(X_test)\n",
    "\n",
    "# features_to_keep = ['WeeksToDeparture', 'week_mean', 'day_mean', 'month_mean', 'day_nb_mean', \n",
    "#                    'route_mean', 'std_wtd', 'n_days_departure']\n",
    "\n",
    "X_train_data = X_train_merged #[features_to_keep]\n",
    "X_test_data = X_test_merged\n",
    "X_train_data.drop(['Departure', 'Arrival', 'holidays_dep', 'holidays_arr'], axis=1, inplace=True) \n",
    "X_test_data.drop(['Departure', 'Arrival', 'holidays_dep', 'holidays_arr'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8902, 73)\n",
      "(2226, 73)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_data.shape)\n",
    "print(X_test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('std_scaler', StandardScaler()),\n",
       "                ('keras_reg',\n",
       "                 <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x138d8f6d0>)])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Keras Model\n",
    "def build_nn():\n",
    "    # create model\n",
    "    model= Sequential(\n",
    "                [Dense(73,activation='relu',input_shape=[73]),\n",
    "                 Dense(36,activation='relu'),\n",
    "                 Dropout(0.2),\n",
    "                 Dense(18,activation='relu'),\n",
    "                 Dense(9,activation='relu'),\n",
    "                 Dense(1)\n",
    "    ])\n",
    "    # compile model\n",
    "    model.compile(optimizer='adam',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['RootMeanSquaredError'])\n",
    "    return model\n",
    "\n",
    "# wrap the model using the function you created\n",
    "keras_reg = KerasRegressor(\n",
    "                build_nn,epochs=100,verbose=False)\n",
    "keras_reg._estimator_type = \"regressor\"\n",
    "\n",
    "# just create the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('std_scaler', StandardScaler()),\n",
    "    ('keras_reg',keras_reg)])\n",
    "\n",
    "pipeline.fit(X_train_data, y_train)\n",
    "# kfold = KFold(n_splits=10)\n",
    "# results = cross_val_score(pipeline, X_train_data, y_train, cv=kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Standardized %.2f (%.2f) MSE\" % (results.mean(), results.std()))\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = pipeline.predict(X_train_data)\n",
    "y_test_pred = pipeline.predict(X_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE: 0.6905525710210727 and Score: -0.4768628180027008\n",
      "Testing RMSE: 0.7692071580888495 and Score: -0.5916798114776611\n"
     ]
    }
   ],
   "source": [
    "score_train = pipeline.score(X_train_data, y_train)\n",
    "score_test = pipeline.score(X_test_data, y_test)\n",
    "\n",
    "rmse_train = mean_squared_error(y_train, y_train_pred, squared=False)\n",
    "rmse_test = mean_squared_error(y_test, y_test_pred, squared=False)\n",
    "\n",
    "print(f\"Training RMSE: {rmse_train} and Score: {score_train}\")\n",
    "print(f\"Testing RMSE: {rmse_test} and Score: {score_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10.476277 10.052585 10.223854 ... 11.114573  9.285128  8.954538]\n",
      "[11.3927145  9.9986315 10.624433  ... 10.238039   9.757681   9.079252 ]\n"
     ]
    }
   ],
   "source": [
    "print(y_test_pred)\n",
    "print(y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
