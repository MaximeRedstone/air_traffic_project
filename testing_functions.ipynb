{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'rampwf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-08332511bd6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mproblem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFunctionTransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'display.max_columns'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/X-HEC/Polytechnique/Semestre 1/Python_For_Data_Science/air_traffic_project/problem.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mrampwf\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mrw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mShuffleSplit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'rampwf'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import problem\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\n",
    "    os.path.join('data', 'train.csv.bz2')\n",
    ")\n",
    "data.loc[:, 'DateOfDeparture'] = pd.to_datetime(data.loc[:, 'DateOfDeparture'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = problem.get_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "def _encode_dates(X):\n",
    "    # With pandas < 1.0, we wil get a SettingWithCopyWarning\n",
    "    # In our case, we will avoid this warning by triggering a copy\n",
    "    # More information can be found at:\n",
    "    # https://github.com/scikit-learn/scikit-learn/issues/16191\n",
    "    X_encoded = X.copy()\n",
    "\n",
    "    # Make sure that DateOfDeparture is of datetime format\n",
    "    X_encoded.loc[:, 'DateOfDeparture'] = pd.to_datetime(X_encoded['DateOfDeparture'])\n",
    "    # Encode the DateOfDeparture\n",
    "    X_encoded.loc[:, 'year'] = X_encoded['DateOfDeparture'].dt.year\n",
    "    X_encoded.loc[:, 'month'] = X_encoded['DateOfDeparture'].dt.month\n",
    "    X_encoded.loc[:, 'day'] = X_encoded['DateOfDeparture'].dt.day\n",
    "    X_encoded.loc[:, 'weekday'] = X_encoded['DateOfDeparture'].dt.weekday\n",
    "    X_encoded.loc[:, 'week'] = X_encoded['DateOfDeparture'].dt.week\n",
    "    X_encoded.loc[:, 'n_days'] = X_encoded['DateOfDeparture'].apply(\n",
    "        lambda date: (date - pd.to_datetime(\"1970-01-01\")).days\n",
    "    )\n",
    "    # Once we did the encoding, we will not need DateOfDeparture\n",
    "#     return X_encoded.drop(columns=[\"DateOfDeparture\"])\n",
    "    return X_encoded\n",
    "\n",
    "date_encoder = FunctionTransformer(_encode_dates)\n",
    "X = date_encoder.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__file__ = os.path.join('submissions', 'starting_kit', 'estimator.py')\n",
    "filepath = os.path.join(os.path.dirname(__file__), 'external_data.csv')\n",
    "filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MergeTransformer():\n",
    "    \"\"\"Custom scaling transformer\"\"\"\n",
    "    \n",
    "    def read_csv_ramp(self, parse_dates=[\"Date\"]):\n",
    "        self.filepath = os.path.join(\n",
    "            self.filepath, self.filename\n",
    "        )\n",
    "        \n",
    "        data = pd.read_csv(os.path.join('data', 'train.csv.bz2'))\n",
    "        if parse_dates is not None:\n",
    "            ext_data = pd.read_csv(self.filepath, parse_dates=parse_dates)\n",
    "        else:\n",
    "            ext_data = pd.read_csv(self.filepath)\n",
    "        return ext_data\n",
    "    \n",
    "    def merge_external_data(self):\n",
    "\n",
    "        X = self.X.copy()  # to avoid raising SettingOnCopyWarning\n",
    "        # Make sure that DateOfDeparture is of dtype datetime\n",
    "        X.loc[:, \"DateOfDeparture\"] = pd.to_datetime(X['DateOfDeparture'])\n",
    "\n",
    "        if not(self.filename is None):\n",
    "            self.X_ext = self.read_csv_ramp(parse_dates=self.parse_dates)\n",
    "\n",
    "        if self.cols_to_keep != 'all':\n",
    "            self.X_ext = self.X_ext[self.cols_to_keep]\n",
    "\n",
    "        if self.cols_to_rename != None:\n",
    "            self.X_ext = self.X_ext.rename(columns=self.cols_to_rename)\n",
    "\n",
    "        X_merged = pd.merge(\n",
    "            X, self.X_ext, how=self.how, on=self.on, sort=False\n",
    "        )\n",
    "        return X_merged\n",
    "\n",
    "    \n",
    "    def __init__(self, X_ext=None, filename=None, filepath='submissions/starting_kit/', cols_to_keep='all', cols_to_rename=None, how='left', on=None, parse_dates=None):\n",
    "#         super().__init__(func)\n",
    "        self.X_ext = X_ext\n",
    "        self.filename = filename\n",
    "        self.filepath = filepath\n",
    "        self.cols_to_keep = cols_to_keep\n",
    "        self.cols_to_rename = cols_to_rename\n",
    "        self.how = how\n",
    "        self.on = on\n",
    "        self.parse_dates = parse_dates\n",
    "        \n",
    "    def fit_transform(self, X):\n",
    "        self.fit(X)\n",
    "        return self.transform()\n",
    "\n",
    "    def fit(self, X):\n",
    "        self.X = X\n",
    "\n",
    "    def transform(self):\n",
    "        return self.merge_external_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_transform = MergeTransformer(\n",
    "    X_ext=None, \n",
    "    filename='external_data.csv',\n",
    "    filepath='submissions/starting_kit/',\n",
    "    cols_to_keep=['Date', 'AirPort', 'Max TemperatureC'], \n",
    "    cols_to_rename={'Date': 'DateOfDeparture', 'AirPort': 'Arrival'}, \n",
    "    how='left',\n",
    "    on=['DateOfDeparture', 'Arrival'],\n",
    "    parse_dates=['Date'])\n",
    "\n",
    "X = merge_transform.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates_data = pd.read_csv('data/list-of-airports-in-united-states-of-america-hxl-tags-1.csv', index_col=0)\n",
    "coordinates_data[coordinates_data.loc[:, 'iata_code'] == 'ORD']\n",
    "\n",
    "coordinates_data.loc[:, 'iso_region'] = coordinates_data.loc[:, 'iso_region'].str.strip('US-')\n",
    "# print(coordinates_data.head())\n",
    "\n",
    "merge_transform = MergeTransformer(\n",
    "    X_ext=coordinates_data, \n",
    "    filename=None,\n",
    "    filepath=None,\n",
    "    cols_to_keep=['latitude_deg', 'longitude_deg', 'iata_code', 'iso_region'], \n",
    "    cols_to_rename={'iata_code': 'Departure',\n",
    "                    'latitude_deg': 'latitude_departure',\n",
    "                    'longitude_deg': 'longitude_departure',\n",
    "                    'iso_region': 'state'}, \n",
    "    how='left',\n",
    "    on=['Departure'],\n",
    "    parse_dates=None)\n",
    "\n",
    "X = merge_transform.fit_transform(X)\n",
    "\n",
    "merge_transform = MergeTransformer(\n",
    "    X_ext=coordinates_data, \n",
    "    filename=None,\n",
    "    filepath=None,\n",
    "    cols_to_keep=['latitude_deg', 'longitude_deg', 'iata_code'], \n",
    "    cols_to_rename={'iata_code': 'Arrival', 'latitude_deg': 'latitude_arrival', 'longitude_deg': 'longitude_arrival'}, \n",
    "    how='left',\n",
    "    on=['Arrival'],\n",
    "    parse_dates=None)\n",
    "\n",
    "X = merge_transform.fit_transform(X)\n",
    "\n",
    "import geopy.distance\n",
    "\n",
    "X['distance'] = X.apply(lambda x: geopy.distance.geodesic(\n",
    "    (x.latitude_departure, x.longitude_departure), \n",
    "    (x.latitude_arrival, x.longitude_arrival)).km, axis=1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_transform = MergeTransformer(\n",
    "    X_ext=None, \n",
    "    filename='oil_price.csv',\n",
    "    filepath='data/',\n",
    "    cols_to_keep=['date', 'value'], \n",
    "    cols_to_rename={'date': 'DateOfDeparture', 'value': 'OilPrice'},\n",
    "    how='left',\n",
    "    on=['DateOfDeparture'],\n",
    "    parse_dates=['date'])\n",
    "\n",
    "X = merge_transform.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import holidays\n",
    "\n",
    "us_holidays = holidays.US(years=2011, state='CA')\n",
    "for key, value in us_holidays.items():\n",
    "    print(f\"key = {key}, value = {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = X.loc[:, 'state'].unique()\n",
    "years = [2011, 2012, 2013]\n",
    "\n",
    "X['bank_holidays'] = X.apply(lambda x: x.DateOfDeparture in holidays.US(years = x.year, state=x.state), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "school_holidays = pd.read_csv('data/holidays.csv', sep=';', parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_transform = MergeTransformer(\n",
    "    X_ext=school_holidays, \n",
    "    filename=None,\n",
    "    filepath=None,\n",
    "    cols_to_keep=['date', 'is_vacation'], \n",
    "    cols_to_rename={'date': 'DateOfDeparture', 'is_vacation': 'school_holidays'},\n",
    "    how='left',\n",
    "    on=['DateOfDeparture'],\n",
    "    parse_dates=None)\n",
    "\n",
    "X = merge_transform.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.loc[:, 'holidays'] = X.loc[:, 'bank_holidays'] | X.loc[:, 'school_holidays']\n",
    "X.drop(['bank_holidays', 'school_holidays'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports_rank = pd.read_csv('data/airports_passengers.csv', sep=';', encoding = \"utf-8\")\n",
    "airports_rank.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('venv': venv)",
   "language": "python",
   "name": "python37764bitvenvvenv0e37d9778044464c8c8e086d087645e5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
